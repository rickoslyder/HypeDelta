# Canonical AI Intelligence Sources: Researchers, Critics, and Media

This comprehensive reference catalogues **200+ AI researchers, critics, and thought leaders** across major labs, academia, and independent channels, plus **50+ essential media sources**. Prioritized for substantive signal—people who share genuine insights about ongoing work, AI progress debates, and field direction.

---

## Section 1: Lab researchers

### Anthropic

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Dario Amodei** | CEO & Co-Founder | @DarioAmodei | darioamodei.com (essays), Lex Fridman #452, Dwarkesh Podcast | Scaling laws, AI safety, RLHF, Constitutional AI | High—infrequent but impactful essays on AI's future implications |
| **Chris Olah** | Co-Founder, Interpretability Lead | @ch402 | colah.github.io, 80,000 Hours Podcast | Mechanistic interpretability, neural network visualization, circuits | Exceptional—legendary blog posts; pioneer of interpretability visualization |
| **Amanda Askell** | Member of Technical Staff | @AmandaAskell | askell.io, Lex Fridman #452 | AI ethics, Constitutional AI, character training, philosophy | High—rigorous philosophical perspective on Claude's development |
| **Jan Leike** | Co-Lead of Alignment Science | @janleike | — | Alignment, scalable oversight, reward modeling, corrigibility | High—vocal on safety concerns; former OpenAI Superalignment co-lead |
| **Jack Clark** | Co-Founder | @jackclarkSF | importai.substack.com | AI policy, strategy, communications | Exceptional—runs the influential Import AI weekly newsletter |
| **Sam McCandlish** | Co-Founder | @samsamoa | LessWrong | Scaling laws, AI safety | Moderate—occasional technical insights |
| **Tom Brown** | Co-Founder | @nottombrown | — | Language modeling, RL, infrastructure | Lower frequency but substantive |
| **Jared Kaplan** | Co-Founder, Chief Science Officer | — | — | Scaling laws, theoretical physics | Less active on social media |

### OpenAI

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Sam Altman** | CEO | @sama | — | AGI strategy, company leadership | High frequency, mix of promotional and substantive; often hints at capabilities |
| **Andrej Karpathy** | Former (now Eureka Labs) | @karpathy | youtube.com/@AndrejKarpathy, karpathy.ai | Computer vision, neural networks, education, autonomous driving | **S-Tier**—coined "vibe coding"; creates legendary educational content |
| **Ilya Sutskever** | Former (now Safe Superintelligence Inc.) | @ilyasut | Dwarkesh Podcast | Deep learning, AGI, superintelligence safety | Rare posts but extremely high impact; pivotal AI figure |
| **Greg Brockman** | Co-Founder & Chairman | @gdb | — | Infrastructure, engineering leadership | Moderate—company updates and technical achievements |
| **Noam Brown** | Researcher | @polynoamial | — | Game theory, Diplomacy AI, poker AI, reasoning | Good technical takes, engages in debates |
| **Lilian Weng** | VP of Research (departed to Thinking Machines) | @lilianweng | lilianweng.github.io | Deep learning, robotics, embeddings, safety | **S-Tier**—reference-quality ML blog posts |
| **Jason Wei** | Former (now Meta Superintelligence Labs) | @_jasonwei | jasonwei.net | Chain-of-thought prompting, instruction tuning, emergent abilities | Exceptional—deep technical insights on reasoning |
| **John Schulman** | Former (now Thinking Machines) | @johnschulman2 | joschu.net, Dwarkesh Podcast | RL, RLHF, PPO algorithm | Technical insights on RL and alignment |

### Google DeepMind

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Demis Hassabis** | Co-Founder & CEO | @demishassabis | Lex Fridman, conferences | AGI, AlphaFold, RL, neuroscience-inspired AI | 2024 Nobel Prize in Chemistry; shares major breakthroughs |
| **Shane Legg** | Co-Founder, Chief AGI Scientist | @ShaneLegg | — | AGI theory, intelligence measurement, SIMA project | Good—thoughts on AGI definitions and timelines |
| **Jeff Dean** | Chief Scientist | @JeffDean | — | Large-scale systems, TensorFlow, Gemini, ML infrastructure | Active—Google AI updates; legendary systems engineer |
| **Oriol Vinyals** | Principal Research Scientist | @OriolVinyalsML | — | Deep learning, seq2seq, RL, AlphaStar | Good technical engagement |
| **Denny Zhou** | Research Scientist, Gemini Reasoning Lead | @denny_zhou | dennyzhou.github.io | Chain-of-thought, LLM reasoning | Technical insights on reasoning research |
| **David Silver** | Principal Research Scientist | — | — | RL, AlphaGo, AlphaZero | Less active on social media |
| **John Jumper** | Principal Research Scientist | — | — | AlphaFold, protein structure prediction | 2024 Nobel Prize co-recipient; limited social presence |
| **Noam Shazeer** | (Returned from Character.AI) | — | — | Transformers, conversational AI | Co-author "Attention Is All You Need"; rare but highly substantive |

### Meta AI / FAIR

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Yann LeCun** | VP & Chief AI Scientist | @ylecun | yann.lecun.com, Lex Fridman (multiple) | CNNs, self-supervised learning, world models, AMI | **S-Tier**—2018 Turing Award; extremely active; provocative debates; challenges AI narratives |
| **Hugo Larochelle** | Research Scientist | @hugo_larochelle | — | Deep learning, representation learning | Good educational content |

### xAI

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Greg Yang** | Co-Founder, Research Lead | @TheGregYang | — | μTransfer, scaling laws, neural network theory | High—deep theoretical insights on scaling |
| **Jimmy Ba** | Co-Founder | @jimmybyba | — | Optimizer design, neural network optimization | High—Adam optimizer co-author; educational content |
| **Yuhuai (Tony) Wu** | Co-Founder | @yuhuaiwu | — | Mathematical reasoning, autoformalization | Moderate—academic-focused |
| **Igor Babuschkin** | Former Chief Engineer | @iabasin | — | Large-scale training, distributed systems | Limited public engagement |

### Mistral AI

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Arthur Mensch** | Co-Founder & CEO | @arthurmensch | No Priors podcast | Efficient LLMs, open-source, mixture-of-experts | High—strategic views on open vs closed AI |
| **Guillaume Lample** | Co-Founder & Chief Scientist | @GusLample | — | NLP, LLMs, translation | Moderate—technical paper announcements |
| **Timothée Lacroix** | Co-Founder & CTO | @tlacroix_ | — | Training infrastructure, model efficiency | Lower public profile |

### Cohere

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Aidan Gomez** | Co-Founder & CEO | @aidangomez | Contrary Research | Transformers, enterprise AI, NLP | High—co-author "Attention Is All You Need"; engages on AI direction |
| **Joëlle Pineau** | Chief AI Officer (joined Aug 2025) | @jpineau | — | RL, robotics, reproducibility | High—academic rigor, policy discussions |
| **Nick Frosst** | Co-Founder | @nickfrosst | — | NLP, knowledge distillation | Moderate engagement |

### Stability AI

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Robin Rombach** | Research Lead | @robinrombach | — | Diffusion models, latent space modeling | High—Stable Diffusion lead author |
| **Patrick Esser** | Research Scientist | @patrick_esser | — | Generative models, video generation | Moderate—technical papers |
| **Andreas Blattmann** | Research Scientist | @a_blattmann | — | Video generation, Stable Video Diffusion | Technical updates on video AI |

### Hugging Face

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Clément Delangue** | Co-Founder & CEO | @ClementDelangue | — | Open-source platforms, community | High—open AI ecosystem advocacy |
| **Thomas Wolf** | Co-Founder & Chief Science Officer | @Thom_Wolf | thomwolf.io, O'Reilly book | Transformers library, open-source ML | High—deep technical education, open science advocacy |
| **Julien Chaumond** | Co-Founder & CTO | @julien_c | — | ML infrastructure, model deployment | High—product/technical updates |
| **Lewis Tunstall** | ML Engineer | @_lewtun | O'Reilly book co-author | NLP fine-tuning, instruction tuning | High—practical ML tutorials |
| **Younes Belkada** | ML Engineer | @younesbelkada | — | Quantization, efficient inference | High—efficiency techniques |

### AI2 (Allen Institute for AI)

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Ali Farhadi** | CEO | @aaborifarhadi | — | Vision-language, open AI | Moderate—organizational announcements |
| **Hanna Hajishirzi** | Senior Director NLP | @HannaHajishirzi | hannaneh.ai | Open LLMs, NLP, OLMo lead | High—open science advocacy |
| **Nathan Lambert** | Research Scientist | @natolambert | interconnects.ai, Interconnects Podcast | RLHF, preference learning, open LLMs | **Exceptional**—best RLHF explainers, industry analysis |
| **Yejin Choi** | Senior Research Director | @yaborejin_choi | — | Commonsense reasoning, AI ethics | High—MacArthur Fellow; thought-provoking capability takes |
| **Oren Etzioni** | Founder (now AI2 Incubator) | @etzioni | — | AI startups, open AI policy | High—AI policy, startup ecosystem |

### NVIDIA Research

| Name | Role | Twitter | Other Platforms | Specialties | Signal Notes |
|------|------|---------|-----------------|-------------|--------------|
| **Jim Fan** | Director of AI, Distinguished Scientist | @DrJimFan | jimfan.me | Embodied AI, robotics, gaming AI, foundation agents | **Exceptional**—prolific posts on robotics and agents; 250K+ followers |
| **Anima Anandkumar** | Senior Director (also Caltech) | @AnimaAnandkumar | — | Tensors, scientific ML, climate AI | High—AI for science, diversity discussions |
| **Sanja Fidler** | VP of AI Research | @sanjafidler | — | Computer vision, 3D understanding | Moderate—technical updates |

### Other Notable Labs

**Apple ML Research:**
- **Samy Bengio** (Senior Director) - Limited Twitter activity
- **Ruslan Salakhutdinov** (VP AI Research, CMU professor) - @rsalakhu, academic-focused

**Amazon AI:**
- **Rohit Prasad** (SVP, AGI Team) - @rohpras, moderate—product announcements
- **Stefano Soatto** (VP, Distinguished Scientist, UCLA professor) - academic-focused

**Runway:**
- **Cristóbal Valenzuela** (Co-Founder & CEO) - @c_valenzuelab, High—engaging AI creativity takes

**Together AI:**
- **Percy Liang** (Co-Founder, Stanford professor) - @pliang, High—HELM benchmarks, model transparency
- **Vipul Ved Prakash** (Co-Founder & CEO) - @vipulved, High—open source advocacy

**Reka AI:**
- **Dani Yogatama** (Co-Founder & CEO) - @DaniYogatama, Moderate—multimodal progress
- **Yi Tay** (Co-Founder) - @ytay, High—scaling insights, architecture takes

**Safe Superintelligence Inc.:**
- **Ilya Sutskever** (Co-Founder & Chief Scientist) - @ilyasut

**Thinking Machines Lab:**
- **Mira Murati** (CEO) - Former OpenAI CTO
- **John Schulman** (Chief Scientist) - @johnschulman2

---

## Section 2: Credentialed critics and skeptics

### LLM understanding and reasoning skeptics

| Name | Affiliation | Twitter | Other Platforms | Main Critique | Skeptical About |
|------|-------------|---------|-----------------|---------------|-----------------|
| **Gary Marcus** | Professor Emeritus, NYU; Robust.AI | @GaryMarcus | garymarcus.substack.com, Lex Fridman, EconTalk | Deep learning alone cannot achieve AGI due to fundamental limitations in reasoning, planning, and reliability | Scaling laws → AGI, LLM reasoning, reliability, AI hype |
| **Emily Bender** | Professor, UW Linguistics | @emilymbender | faculty.washington.edu/ebender, TIME100 AI 2023 | LLMs are "stochastic parrots"—they stitch together linguistic forms without reference to meaning | LLM "understanding," corporate AI hype, environmental costs |
| **Melanie Mitchell** | Professor, Santa Fe Institute | @MelMitchell1 | aiguide.substack.com, melaniemitchell.me, Lex Fridman | Current AI lacks genuine understanding, abstraction, and analogical reasoning; benchmarks are inadequate | AGI timelines, LLM understanding, benchmark validity |
| **François Chollet** | Co-founder ARC Prize; Keras creator | @fchollet | fchollet.com, ARC benchmark | Intelligence is skill-acquisition efficiency, not narrow task performance; current AI lacks genuine abstraction | Pure scaling approaches, benchmark gaming, LLM reasoning claims |

### AI safety and existential risk concerned

| Name | Affiliation | Twitter | Other Platforms | Main Critique | Skeptical About |
|------|-------------|---------|-----------------|---------------|-----------------|
| **Yoshua Bengio** | Professor, Montréal; Mila founder; LawZero | @yoshuabengio | yoshuabengio.org, 2018 Turing Award | AGI poses catastrophic/existential risks; current safety methods inadequate; need "safe-by-design" AI | Adequacy of current safety measures, corporate self-regulation |
| **Geoffrey Hinton** | Professor Emeritus, Toronto; Vector Institute | — | 60 Minutes, MIT Tech Review, 2024 Nobel Prize Physics | AI developing potentially superior intelligence; poses existential risks including loss of control | Ability to control superintelligent AI, humanity's preparedness |
| **Stuart Russell** | Professor, UC Berkeley; CHAI founder | — | people.eecs.berkeley.edu/~russell, "Human Compatible" (2019) | Current AI paradigm fundamentally misaligned; systems need uncertainty about human preferences | Current alignment approaches, near-term AGI claims |

### AGI timeline and capability skeptics

| Name | Affiliation | Twitter | Other Platforms | Main Critique | Skeptical About |
|------|-------------|---------|-----------------|---------------|-----------------|
| **Rodney Brooks** | Professor Emeritus, MIT; Robust.AI | @rodneyabrooks | rodneybrooks.com (annual predictions scorecard) | AI hype dramatically overestimates timelines; confuses performance with competence | Humanoid robots, self-driving timelines, AGI timelines, AI replacing workers soon |
| **Yann LeCun** | Chief AI Scientist, Meta; NYU | @ylecun | yann.lecun.com | LLMs fundamentally limited—lack world understanding, persistent memory, true reasoning; calls them "a dead end" for AGI | LLM path to AGI, scaling alone achieving intelligence |

### AI ethics and bias critics

| Name | Affiliation | Twitter | Other Platforms | Main Critique | Skeptical About |
|------|-------------|---------|-----------------|---------------|-----------------|
| **Timnit Gebru** | Founder, DAIR Institute | @timnitGebru | TIME 100 2022, Nature's 10 2021 | AI development driven by profit over ethics; perpetuates bias; corporate labs cannot self-regulate | Corporate ethics commitments, TESCREAL ideologies, Big Tech influence |
| **Arvind Narayanan & Sayash Kapoor** | Professors, Princeton | — | aisnakeoil.com, "AI Snake Oil" book (2024) | Focus on separating genuine AI capabilities from hype; document how AI is oversold | AI hype in specific applications, benchmark validity |

---

## Section 3: Independent researchers and commentators

### Independent researchers

| Name | Affiliation | Twitter | Other Platforms | Focus Areas | Signal Notes |
|------|-------------|---------|-----------------|-------------|--------------|
| **Eliezer Yudkowsky** | Founder, MIRI | @ESYudkowsky | LessWrong, "If Anyone Builds It, Everyone Dies" (2025) | AI alignment, existential risk, decision theory | Foundational thinker on AI safety; autodidact who pioneered discourse |
| **Jeremy Howard** | Co-founder, fast.ai & answer.ai | @jeremyphoward | youtube.com/@howardjeremyp | Practical AI education, transfer learning, ULMFiT | Champion of accessible, practical AI education |
| **Simon Willison** | Independent; Datasette creator | @simonw | simonwillison.net (23 years!), Mastodon | LLM practical applications, prompt injection security | Exceptional—no-hype approach; coined "prompt injection"; endorsed by Karpathy |
| **Scott Aaronson** | Professor, UT Austin | — | scottaaronson.blog | Quantum computation, AI safety | Rigorous theoretical perspective on safety debates |
| **John Carmack** | Independent AI researcher | @ID_AA_Carmack | — | AI/AGI research, optimization | Unique engineering perspective from legendary game developer |

### AI-focused journalists

| Name | Outlet | Twitter | Focus Areas | Signal Notes |
|------|--------|---------|-------------|--------------|
| **Cade Metz** | The New York Times | @CadeMetz | AI, robotics, emerging tech | Author "Genius Makers"; deep technical understanding |
| **Jeremy Kahn** | Fortune (AI Editor) | @jeremykahn | AI business, policy | Author "Mastering AI"; strong business perspective |
| **Deepa Seetharaman** | The Wall Street Journal | — | AI business, industry competition | Influential coverage of OpenAI, DeepSeek |
| **Will Knight** | WIRED (Senior Writer) | @willknight | AI, ML, tech trends | Sophisticated technical coverage |
| **Karen Hao** | Previously MIT Tech Review | — | AI algorithms, social impact | Sophisticated AI coverage with social lens |
| **Benj Edwards** | Ars Technica | — | AI/ML developments, tech history | Technically literate reporting |

### YouTubers doing paper reviews / technical analysis

| Channel | Host | Subscribers | Content Focus | Signal Notes |
|---------|------|-------------|---------------|--------------|
| **Yannic Kilcher** | Yannic Kilcher | ~280K | In-depth paper reviews, ML news, critiques | Exceptional—thorough read-throughs with honest critiques |
| **Two Minute Papers** | Károly Zsolnai-Fehér | 1.7M+ | Quick research paper summaries | High—accessible to non-experts; "What a time to be alive!" |
| **AI Explained** | Philip (anon) | — | AI news analysis, model comparisons | Very high—hype-free; read by OpenAI/Microsoft professionals |
| **Andrej Karpathy** | Andrej Karpathy | ~220K | Neural networks from scratch, LLM deep dives | Exceptional—3.5-hour ChatGPT video; nanoGPT |
| **Machine Learning Street Talk** | Tim Scarfe, Keith Duggar, Connor Shorten | — | Long-form technical discussions | Very high—guests include LeCun, Chollet, Russell |
| **Dwarkesh Patel** | Dwarkesh Patel | — | In-depth AI intellectual interviews | Very high—guests include Zuckerberg, Jeff Dean, Dario Amodei |
| **StatQuest** | Josh Starmer | — | Statistics, ML math fundamentals | Essential for understanding fundamentals |
| **3Blue1Brown** | Grant Sanderson | — | Math/neural network visualizations | Very high—conceptual clarity |
| **Sentdex** | Harrison Kinsley | — | Python ML tutorials, implementations | High—practical implementation |

### Key AI Twitter/X personalities

| Name | Handle | Affiliation | Focus | Signal Notes |
|------|--------|-------------|-------|--------------|
| **Fei-Fei Li** | @drfeifei | Stanford HAI, ImageNet | Computer vision, human-centered AI | Academic rigor with real-world applications |
| **Kate Crawford** | @katecrawford | Research Professor | AI ethics, social implications | Critical perspective; "Atlas of AI" author |
| **Erik Brynjolfsson** | @erikbrynjolfsson | Stanford Digital Economy Lab | AI economics, productivity | Rigorous economic analysis of AI impact |
| **Connor Leahy** | @NPCollapse | CEO, Conjecture | AI safety, alignment | Substantive safety discourse |
| **Kirk Borne** | @KirkDBorne | Booz Allen Hamilton | Data science, ML, astrophysics | Influential data science voice |

---

## Section 4: Key Substacks and newsletters

### Tier 1: High-signal technical / research focus

| Newsletter | URL | Author(s) | Focus | Frequency | Signal Quality |
|------------|-----|-----------|-------|-----------|----------------|
| **Import AI** | importai.substack.com | Jack Clark (Anthropic co-founder) | Cutting-edge research, technical papers | Weekly | High signal, high technical depth |
| **The Gradient** | thegradient.pub | Daniel Bashir + Stanford AI Lab | AI research, interviews | 2-3x/month | High signal, research-focused |
| **AI Snake Oil** | aisnakeoil.com | Arvind Narayanan & Sayash Kapoor | AI hype debunking, research critique | Weekly | High signal, academic rigor |
| **Interconnects** | interconnects.ai | Nathan Lambert (AI2) | RLHF, alignment, open-source LLMs | Weekly | Very high, extremely technical |
| **Ahead of AI** | magazine.sebastianraschka.com | Sebastian Raschka | LLM research papers, implementation | Weekly | High signal, very technical |
| **Latent Space** | latent.space | swyx + Alessio | AI engineering, foundation models, agents | Weekly | High signal, practitioner-focused |
| **The Batch** | deeplearning.ai/the-batch | Andrew Ng / DeepLearning.AI | Industry news, research summaries | Weekly | High signal, accessible |
| **AI: A Guide for Thinking Humans** | aiguide.substack.com | Melanie Mitchell | AI fundamentals, misconceptions | Monthly | High signal, conceptual depth |

### Tier 2: Industry analysis and policy

| Newsletter | URL | Author(s) | Focus | Frequency | Signal Quality |
|------------|-----|-----------|-------|-----------|----------------|
| **One Useful Thing** | oneusefulthing.org | Ethan Mollick (Wharton) | Practical AI applications, business | 2-3x/week | High signal, business-focused |
| **SemiAnalysis** | semianalysis.com | Dylan Patel | AI chips, GPU markets, semiconductors | Weekly | High signal, hardware focus |
| **Hyperdimensional** | hyperdimensional.co | Dean W. Ball | AI policy, governance, economics | Weekly | High signal, policy focus |
| **The Algorithmic Bridge** | thealgorithmicbridge.com | Alberto Romero | AI ethics, LLM analysis | Weekly | Medium-high signal |

### Tier 3: Safety, alignment, and x-risk

| Newsletter | URL | Author(s) | Focus | Frequency | Signal Quality |
|------------|-----|-----------|-------|-----------|----------------|
| **Don't Worry About the Vase** | thezvi.substack.com | Zvi Mowshowitz | AI safety, rationality, policy | Weekly | High signal, detailed analysis |
| **Astral Codex Ten** | astralcodexten.substack.com | Scott Alexander | AI content among broader topics | Variable | High signal (AI subset) |
| **AI Safety Newsletter** | newsletter.safe.ai | Dan Hendrycks team | AI safety research, risk assessment | Monthly | High signal, safety focus |

### Tier 4: Curation and daily updates

| Newsletter | URL | Author(s) | Focus | Frequency | Signal Quality |
|------------|-----|-----------|-------|-----------|----------------|
| **The Rundown AI** | therundown.ai | Rowan Cheung | AI news overview | Daily | Medium-high, comprehensive |
| **Ben's Bites** | bensbites.beehiiv.com | Ben Tossell | AI news, product launches | Daily | Medium-high, business perspective |
| **Last Week in AI** | lastweekin.ai | Multiple | Weekly summaries | Weekly | Medium signal |
| **NLP News** | newsletter.ruder.io | Sebastian Ruder (DeepMind) | NLP advances, multilingual | Monthly | High signal, NLP-specific |
| **Simon Willison's Newsletter** | simonw.substack.com | Simon Willison | LLMs, tools, practical apps | Weekly | High signal, developer-focused |

---

## Section 5: Podcasts and YouTube channels

### Research and technical interview podcasts

| Podcast | Host(s) | Focus | Notable Guests | Frequency |
|---------|---------|-------|----------------|-----------|
| **Machine Learning Street Talk** | Tim Scarfe, Keith Duggar, Connor Shorten | Deep technical paper discussions | Yann LeCun, Joscha Bach, François Chollet, Stuart Russell | Weekly |
| **AXRP** | Daniel Filan | AI safety research papers | Evan Hubinger, Rohin Shah, Andrew Critch | 2x/month |
| **The Gradient Podcast** | Daniel Bashir | AI research discussions | Diverse academics and practitioners | Weekly |
| **Latent Space** | swyx + Alessio | AI engineering, foundation models | Chris Lattner, Andrej Karpathy, George Hotz, Jeremy Howard | Weekly |
| **TWIML AI** | Sam Charrington | ML/AI research, applications | Sara Hooker, diverse researchers | 2x/week |

### Long-form intellectual discussions

| Podcast | Host(s) | Focus | Notable Guests | Frequency |
|---------|---------|-------|----------------|-----------|
| **Lex Fridman Podcast** | Lex Fridman (MIT) | AI episodes among broader topics | Sam Altman, Yann LeCun, Demis Hassabis, Ilya Sutskever | 2-3x/week |
| **Dwarkesh Podcast** | Dwarkesh Patel | In-depth AI discussions | Mark Zuckerberg, Jeff Dean, Dario Amodei, Leopold Aschenbrenner | Weekly |
| **80,000 Hours** | Rob Wiblin | AI safety, effective altruism | Stuart Russell, Paul Christiano, Holden Karnofsky | 2x/month |
| **The Robot Brains** | Pieter Abbeel (UC Berkeley) | Robotics, RL, AI research | Chelsea Finn, Sergey Levine | Weekly |

### Industry and applied focus

| Podcast | Host(s) | Focus | Frequency |
|---------|---------|-------|-----------|
| **The Cognitive Revolution** | Nathan Labenz | AI applications, business | 2x/week |
| **Gradient Dissent** | Weights & Biases team | ML ops, deep learning | Weekly |
| **Practical AI** | Chris Benson, Daniel Whitenack | Accessible AI/ML | Weekly |
| **Hard Fork** | Kevin Roose, Casey Newton (NYT) | Tech/AI news | 2x/week |

### YouTube channels by category

**Paper reviews and technical explanations:**
- **Yannic Kilcher** (youtube.com/@YannicKilcher) — In-depth paper reviews with honest critiques
- **Two Minute Papers** (youtube.com/@TwoMinutePapers) — Quick, accessible research summaries
- **AI Explained** (youtube.com/@AIExplained-official) — Hype-free news analysis
- **Machine Learning Street Talk** — Long-form technical discussions
- **The AI Epiphany** (youtube.com/@TheAIEpiphany) — Paper implementations with code

**Tutorials and educational:**
- **Andrej Karpathy** (youtube.com/@AndrejKarpathy) — Neural networks from scratch
- **3Blue1Brown** (youtube.com/@3blue1brown) — Math/neural network visualizations
- **StatQuest** (youtube.com/@statquest) — Statistics and ML algorithms explained
- **DeepLearning.AI** (youtube.com/@Deeplearningai) — ML courses
- **Sentdex** (youtube.com/@sentdex) — Python ML tutorials

**News and analysis:**
- **Dwarkesh Patel** (youtube.com/@DwarkeshPatel) — Long-form interviews
- **Lex Fridman** (youtube.com/@lexfridman) — Interview videos
- **Matt Wolfe** — AI tools and product reviews
- **Wes Roth** — AI news and developments

---

## Section 6: Blogs

### Major AI lab blogs

| Blog | URL | Focus | Frequency |
|------|-----|-------|-----------|
| **Anthropic Research** | anthropic.com/research | Constitutional AI, interpretability, safety | Monthly |
| **OpenAI Blog** | openai.com/blog | Model releases, research announcements | Weekly |
| **Google DeepMind Blog** | deepmind.google/discover/blog | AlphaFold, Gemini, foundational research | Weekly |
| **Google AI Blog** | ai.googleblog.com | Research across ML/AI domains | 2-3x/week |
| **Meta AI Blog** | ai.meta.com/blog | Llama, open-source models | Weekly |

### Individual researcher blogs (high technical depth)

| Blog | URL | Author | Focus | Notable Posts |
|------|-----|--------|-------|---------------|
| **Lil'Log** | lilianweng.github.io | Lilian Weng | RL, transformers, agents, safety | "LLM-Powered Autonomous Agents" |
| **Jay Alammar** | jalammar.github.io | Jay Alammar | Visual ML explanations | "The Illustrated Transformer," "Illustrated BERT" |
| **Sebastian Ruder** | ruder.io | Sebastian Ruder (DeepMind) | NLP, transfer learning | "Gradient Descent Overview" |
| **colah's blog** | colah.github.io | Chris Olah (Anthropic) | Neural network visualizations, interpretability | LSTM explainer, feature visualization |
| **karpathy.github.io** | karpathy.github.io | Andrej Karpathy | Neural networks, deep learning | "The Unreasonable Effectiveness of RNNs" |
| **Rodney Brooks** | rodneybrooks.com | Rodney Brooks | Robotics, AI predictions | Annual Predictions Scorecard |

### Community and educational platforms

| Platform | URL | Focus | Notes |
|----------|-----|-------|-------|
| **AI Alignment Forum** | alignmentforum.org | Technical alignment research | Daily posts from researchers |
| **LessWrong (AI tag)** | lesswrong.com/tag/ai | AI safety, rationality | Diverse AI risk discussions |
| **Distill.pub** | distill.pub | Interactive ML research | **Inactive since 2021**—archived content valuable |
| **Towards Data Science** | towardsdatascience.com | ML tutorials | Varied quality; needs curation |
| **Machine Learning Mastery** | machinelearningmastery.com | Practical tutorials | Comprehensive tutorial library |

### Institutional research blogs

| Blog | URL | Organization | Frequency |
|------|-----|--------------|-----------|
| **BAIR Blog** | bair.berkeley.edu/blog | UC Berkeley AI Research | Monthly |
| **Stanford AI Lab Blog** | ai.stanford.edu/blog | Stanford HAI | Monthly |
| **Microsoft Research Blog** | microsoft.com/en-us/research/blog | Microsoft Research | Weekly |
| **AWS ML Blog** | aws.amazon.com/blogs/machine-learning | Amazon | Weekly |

---

## Quick reference: Signal quality tiers

### S-Tier (must-follow for substantive, frequent, technically deep content)
- **@karpathy** (Andrej Karpathy) — Educational content king
- **@ylecun** (Yann LeCun) — Debates, contrarian takes, world models
- **@ch402** (Chris Olah) — Interpretability pioneer, legendary blog
- **@_jasonwei** (Jason Wei) — Chain-of-thought insights
- **@lilianweng** (Lilian Weng) — Reference-quality blog posts
- **@fchollet** (François Chollet) — Intelligence measurement, framework insights
- **@DrJimFan** (Jim Fan) — Robotics, agents, predictions
- **@natolambert** (Nathan Lambert) — RLHF deep dives, open AI
- **@simonw** (Simon Willison) — Practical LLM applications, no hype

### A-Tier (high quality, good frequency)
- **Jack Clark** — Import AI newsletter
- **@janleike** (Jan Leike) — Safety-focused insights
- **@AmandaAskell** (Amanda Askell) — Philosophy of AI
- **@GaryMarcus** (Gary Marcus) — AI limitations critique
- **@demishassabis** (Demis Hassabis) — DeepMind breakthroughs
- **@JeffDean** (Jeff Dean) — Systems and infrastructure
- **@arthurmensch** (Arthur Mensch) — Open vs closed, efficiency
- **@aidangomez** (Aidan Gomez) — Enterprise AI, transformer history

### Notable recent movements (2024-2025)
- **OpenAI departures:** Ilya Sutskever → Safe Superintelligence Inc.; Mira Murati, John Schulman → Thinking Machines Lab; Jan Leike → Anthropic; Many → Meta Superintelligence Lab
- **Jason Wei:** Google Brain → OpenAI → Meta Superintelligence Labs
- **Noam Shazeer/Daniel De Freitas:** Character.AI → Google DeepMind (acqui-hire)
- **FAIR restructuring:** Joëlle Pineau departed → Cohere; Yann LeCun temporarily leading; layoffs late 2025
- **Lilian Weng:** OpenAI VP Safety → Thinking Machines Lab

---

## Platform migration notes

Many researchers are increasingly active on **Bluesky** as an alternative to X/Twitter:
- Rodney Brooks: @rodneyabrooks.bsky.social
- Melanie Mitchell: Primarily posting on Bluesky now
- Growing AI safety community on Bluesky

**Key platforms by content type:**
- **Technical deep-dives:** colah.github.io, lilianweng.github.io, jalammar.github.io
- **AI policy/news:** Import AI newsletter, 80,000 Hours Podcast
- **Video education:** Andrej Karpathy YouTube, 3Blue1Brown
- **Debates/hot takes:** Yann LeCun, François Chollet, Gary Marcus on Twitter
- **Interpretability:** Chris Olah blog, Anthropic research page
- **Safety discourse:** Jan Leike, Amanda Askell, AI Alignment Forum, LessWrong